{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (29669331.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install rest_framework\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install rest_framework\n",
    "pip install django-cors-headers\n",
    "pip install djangorestframework-jwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rest_framework'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrest_framework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api_view\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrest_framework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m status\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrest_framework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Response\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rest_framework'"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from rest_framework.decorators import api_view\n",
    "from rest_framework import status\n",
    "from rest_framework.response import Response\n",
    "from Face_Recognation.serializer import Register_Image_Serializer\n",
    "import os, base64, io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras_facenet import FaceNet\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Initialize the FaceNet model and MTCNN for face detection\n",
    "facenet_model = FaceNet()\n",
    "detector = MTCNN()\n",
    "\n",
    "@api_view(['POST'])\n",
    "def Register_Image(request):\n",
    "    serializer = Register_Image_Serializer(data=request.data)\n",
    "\n",
    "    if serializer.is_valid(raise_exception=True):\n",
    "        _, image_data = request.data['image'].split(',')\n",
    "        image_filename = f\"{request.data['student_Id']}.png\"  # You can set your desired filename\n",
    "        image_path = os.path.join(\"/home/sahil/Student-Record-Management-System/Backend/Face_Recognation/media_image\", image_filename)\n",
    "\n",
    "        print(image_path)\n",
    "        # Decode and save the image\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(base64.b64decode(image_data))\n",
    "\n",
    "        # Load the image and detect the face using MTCNN\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "        face_detections = detector.detect_faces(image_np)\n",
    "\n",
    "        if len(face_detections) != 1:\n",
    "            # Handle the case when no face or multiple faces are detected\n",
    "            return Response({\"error\": \"Invalid number of faces detected.\"}, status=status.HTTP_400_BAD_REQUEST)\n",
    "\n",
    "        # Crop the face region\n",
    "        x, y, width, height = face_detections[0]['box']\n",
    "        face_image = image_np[y:y+height, x:x+width]\n",
    "\n",
    "        # Generate face embeddings using FaceNet\n",
    "        face_encoding = facenet_model.embeddings([face_image])[0]\n",
    "        print(face_encoding)\n",
    "\n",
    "        # Save the encoding as a .npy file\n",
    "        save_folder = \"./encoding_folder\"\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "\n",
    "        encoding_filename = f\"{request.data['student_Id']}.npy\"\n",
    "        encoding_path = os.path.join(save_folder, encoding_filename)\n",
    "\n",
    "        np.save(encoding_path, face_encoding)\n",
    "\n",
    "        serializer.save()\n",
    "        return Response({\"success\": \"Image registered successfully\"}, status=status.HTTP_201_CREATED)\n",
    "\n",
    "    return Response(serializer.data, status=status.HTTP_401_UNAUTHORIZED)\n",
    "\n",
    "\n",
    "@api_view(['POST'])\n",
    "def image_verification(request):\n",
    "    # Loading the verification image encoding from the .npy file\n",
    "    verification_images_save_folder = \"./encoding_folder\"\n",
    "    verification_img_encoding_filename = f\"{request.data['student_Id']}.npy\"\n",
    "    verification_img_encoding_path = os.path.join(verification_images_save_folder, verification_img_encoding_filename)\n",
    "\n",
    "    if os.path.exists(verification_img_encoding_path):\n",
    "        verification_img_encoding = np.load(verification_img_encoding_path)\n",
    "        print(\"Shape of loaded image encoding:\", verification_img_encoding.shape)\n",
    "    else:\n",
    "        return Response({\"message\": \"File not found.\"}, status=status.HTTP_404_NOT_FOUND)\n",
    "\n",
    "    # Decode the captured image\n",
    "    _, captured_image_data = request.data['image'].split(',')\n",
    "    captured_decoded_image = base64.b64decode(captured_image_data)\n",
    "    captured_image = Image.open(io.BytesIO(captured_decoded_image))\n",
    "    captured_image = captured_image.convert(\"RGB\")\n",
    "    captured_image_np = np.array(captured_image)\n",
    "\n",
    "    # Detect face in the captured image\n",
    "    captured_face_detections = detector.detect_faces(captured_image_np)\n",
    "\n",
    "    if len(captured_face_detections) != 1:\n",
    "        return Response({\"message\": \"Multiple or no faces detected.\"}, status=status.HTTP_400_BAD_REQUEST)\n",
    "\n",
    "    # Crop the face region\n",
    "    x, y, width, height = captured_face_detections[0]['box']\n",
    "    captured_face_image = captured_image_np[y:y+height, x:x+width]\n",
    "\n",
    "    # Generate face encoding for the captured image\n",
    "    captured_img_encoding = facenet_model.embeddings([captured_face_image])[0]\n",
    "\n",
    "    # Compute Euclidean distance between embeddings\n",
    "    distance = norm(verification_img_encoding - captured_img_encoding)\n",
    "\n",
    "    # Set a threshold for face similarity (adjust this based on experimentation)\n",
    "    threshold = 1.4  # Adjust this value based on your experiments\n",
    "    print(distance)\n",
    "    if distance < threshold:\n",
    "        return Response({\"message\": \"success\"}, status=status.HTTP_200_OK)\n",
    "    else:\n",
    "        return Response({\"message\": \"failure\"}, status=status.HTTP_200_OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_3831",
   "language": "python",
   "name": "gg_3831"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
